import jieba
import json

# testData = "我很喜欢我的妈妈和我的爸爸"

def tokenisation(input):
    tokenise = jieba.cut(input, cut_all=True)
    segmented = "/ ".join(tokenise)

    inputSplit = []
    inputSplit.append(segmented.split("/"))

    return inputSplit

def comparisonScoring(Response):
    tokenisedInp = tokenisation(Response)
    followupQes = ["你喜欢什么中学课吗?", "为什么你选了你的课吗?"]
    relevancyScore = 0

    for i in followupQes:
        tokenisedQes = tokenisation(followupQes[i])
        for j in tokenisedInp:
            if tokenisedInp[i] == tokenisedQes[j]:
                


    # file = open("TrainingData.txt", "r+")
    # for line in file:

    # file.close()



# Potential Things to be added:
# 1. Takes a database of replies to a certain question that admins can select as appropriate or not, which is then used to score the user responses based off keywords, length etc. 
#    Can also send this feedback to the user that wrote the repsponse for the reason it was selected as inappropriate
# 2. Sorts the responses in text files/ other appropriate databases by keywords and original questions, making the search for comparable texts more resource efficient and quick


# testData = "我很喜欢我的妈妈和我的爸爸"
# print(tokenisation(testData))

# file = open('TrainingData.json')
# data = json.load(file)
