from cgi import test
from lib2to3.pgen2 import token
import re
import jieba
import json

testData = "我有很多好的中学课"

def tokenise(input):
    tokenise = jieba.cut(input, cut_all=True)
    segmented = "/".join(tokenise)

    inputSplit = segmented.split("/")
    return inputSplit

def comparisonScoring(Response):
    tokenisedInp = tokenise(Response)
    followupQes = ["你喜欢什么中学课吗?", "为什么你选了你的课吗?"] # stub for database

    relevancyArray = []
    i = 0
    while i < len(followupQes):
        tokenisedQes = tokenise(followupQes[i])
        # Need a function to strip filler pronouns/grammar items/particles/repeating tokens to make the process more accurate
        relevancyCount = 0
        l = 0
        while l < len(tokenisedQes):
            j = 0
            while j < len(tokenisedInp):
                if tokenisedInp[j] == tokenisedQes[l]:
                    relevancyCount = relevancyCount + 1
                    print(relevancyCount)
                j = j + 1

            relevancyScore = relevancyCount/len(tokenisedInp)
            relevancyArray.append(relevancyScore)
            l = l + 1
        print("The relevancy score for the", i, "iteration is:", relevancyScore)
        i = i + 1

    return relevancyArray

# print(tokenise(testData))
comparisonScoring(testData)
                


    # file = open("TrainingData.txt", "r+")
    # for line in file:

    # file.close()



# Potential Things to be added:
# 1. Takes a database of replies to a certain question that admins can select as appropriate or not, which is then used to score the user responses based off keywords, length etc. 
#    Can also send this feedback to the user that wrote the repsponse for the reason it was selected as inappropriate
# 2. Sorts the responses in text files/ other appropriate databases by keywords and original questions, making the search for comparable texts more resource efficient and quick


# testData = "我很喜欢我的妈妈和我的爸爸"