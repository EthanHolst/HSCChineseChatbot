from cgi import test
from lib2to3.pgen2 import token
import re
import jieba
import json

# testData = "我很喜欢我的妈妈和我的爸爸"

def tokenise(input):
    tokenise = jieba.cut(input, cut_all=True)
    segmented = "/ ".join(tokenise)

    inputSplit = []
    inputSplit.append(segmented.split("/"))

    return inputSplit

def comparisonScoring(Response):
    tokenisedInp = tokenise(Response)
    followupQes = ["你喜欢什么中学课吗?", "为什么你选了你的课吗?"] #stub for database

    relevancyCount = 0
    relevancyArray = []

    for i in followupQes:
        tokenisedQes = tokenise(followupQes[i])
        # Need a function to strip filler pronouns/grammar items/particles to make the process more accurate
        for j in tokenisedInp:
            if tokenisedInp[i] == tokenisedQes[j]:
                relevancyCount = relevancyCount + 1

    relevancyScore = relevancyCount/tokenisedInp
    relevancyArray.append(relevancyScore)


                


    # file = open("TrainingData.txt", "r+")
    # for line in file:

    # file.close()



# Potential Things to be added:
# 1. Takes a database of replies to a certain question that admins can select as appropriate or not, which is then used to score the user responses based off keywords, length etc. 
#    Can also send this feedback to the user that wrote the repsponse for the reason it was selected as inappropriate
# 2. Sorts the responses in text files/ other appropriate databases by keywords and original questions, making the search for comparable texts more resource efficient and quick


# testData = "我很喜欢我的妈妈和我的爸爸"
# print(tokenise(testData))